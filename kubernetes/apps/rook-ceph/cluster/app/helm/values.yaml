---
# Rook Ceph Cluster Configuration
# 3-node cluster with device selectors for each node
monitoring:
  enabled: true
  createPrometheusRules: true

ingress:
  dashboard:
    enabled: false

cephClusterSpec:
  cleanupPolicy:
    wipeDevicesFromOtherClusters: true
  mon:
    count: 3
    allowMultiplePerNode: false
  mgr:
    count: 2
    allowMultiplePerNode: false
  dashboard:
    enabled: true
    ssl: false
  crashCollector:
    disable: false
  storage:
    useAllNodes: false
    useAllDevices: false
    nodes:
    - name: "rias"
      devicePathFilter: "/dev/disk/by-id/scsi-0QEMU_QEMU_HARDDISK_drive-scsi2"
      config:
        deviceClass: "ssd"
        metadataDevice: ""
        osdsPerDevice: "1"
    - name: "nami"
      devicePathFilter: "/dev/disk/by-id/ata-CT2000BX500SSD1_2513E9B2B5A5"
      config:
        deviceClass: "ssd"
        metadataDevice: ""
        osdsPerDevice: "1"
    - name: "marin"
      devicePathFilter: "/dev/disk/by-id/nvme-Samsung_SSD_970_EVO_Plus_1TB_S6S1NJ0TB03807K"
      config:
        deviceClass: "ssd"
        metadataDevice: ""
        osdsPerDevice: "1"

# Storage classes configuration - using defaults
cephBlockPools:
- name: ceph-blockpool
  spec:
    failureDomain: host
    replicated:
      size: 3
      requireSafeReplicaSize: true
  storageClass:
    enabled: true
    name: ceph-block
    isDefault: true
    reclaimPolicy: Delete
    allowVolumeExpansion: true
    volumeBindingMode: Immediate
    parameters:
      imageFormat: "2"
      imageFeatures: layering
      csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
      csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
      csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
      csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
      csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
      csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
      csi.storage.k8s.io/fstype: ext4

cephFileSystems:
- name: ceph-filesystem
  spec:
    metadataPool:
      replicated:
        size: 3
    dataPools:
    - name: data0
      failureDomain: host
      replicated:
        size: 3
    metadataServer:
      activeCount: 1
      activeStandby: true
  storageClass:
    enabled: true
    name: ceph-filesystem
    pool: data0
    reclaimPolicy: Delete
    allowVolumeExpansion: true
    volumeBindingMode: Immediate
    parameters:
      csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
      csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
      csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
      csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
      csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
      csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
      csi.storage.k8s.io/fstype: ext4

cephObjectStores:
- name: ceph-objectstore
  spec:
    metadataPool:
      failureDomain: host
      replicated:
        size: 3
    dataPool:
      failureDomain: host
      erasureCoded:
        dataChunks: 2
        codingChunks: 1
    preservePoolsOnDelete: true
    gateway:
      sslCertificateRef:
      port: 80
      instances: 1
      priorityClassName:
  storageClass:
    enabled: true
    name: ceph-bucket
    reclaimPolicy: Delete
    volumeBindingMode: Immediate
    parameters:
      region: us-east-1
